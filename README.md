# scrapy_parser_pep

**scrapy_parser_pep**  - пример работы асинхронного парсера scrapy 

## Функции приложения

- Получение информации о всех актуальных версиях Python и их статусов
- Выгрузка в файл csv.

## Стек технологий

### Backend

- Python(Scrapy)

### Инструменты разработки
- Git (система контроля версий)

## Развертывание проекта

1. Клонируйте репозиторий:

   git clone https://github.com/DmitryAlexandrov91/scrapy_parser_pep.git

2. Разверните виртуальное окружение и установите зависимости из файла requiremetns.txt *(проект разработан на версии Python 3.19)*

При активированном виртуальном окружении выполните команду **scrapy crawl pep** для запуска программы.

В директории results сохранятся два файла csv с результатами парсинга.
Настройки названия директории содержатся в файле constants.py в директории pep_parse.

## Автор

Александров Дмитрий

<u>GitHub</u>
 - https://github.com/DmitryAlexandrov91


